{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "了解如何使用 Sklearn 中的 hyper-parameter search 找出最佳的超參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業\n",
    "請使用不同的資料集，並使用 hyper-parameter search 的方式，看能不能找出最佳的超參數組合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes()\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 905.4545327948354\n",
      "test loss: 3203.1262904754335\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size = 0.25, random_state = 42)\n",
    "reg = GradientBoostingRegressor(random_state = 20)\n",
    "reg.fit(x_train, y_train)\n",
    "y_pred = reg.predict(x_test)\n",
    "print(f'train loss: {metrics.mean_squared_error(y_train, reg.predict(x_train))}')\n",
    "print(f'test loss: {metrics.mean_squared_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search CV Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:   27.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='ls', max_depth=3,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=100,\n",
       "                                                 n_ite...one,\n",
       "                                                 presort='deprecated',\n",
       "                                                 random_state=20, subsample=1.0,\n",
       "                                                 tol=0.0001,\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.001, 0.01, 0.1, 1],\n",
       "                         'max_depth': [1, 3, 5, 7],\n",
       "                         'n_estimators': [50, 100, 200, 300]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning = [0.001, 0.01, 0.1, 1]\n",
    "n_estimators = [50, 100, 200, 300]\n",
    "max_depth = [1, 3, 5, 7]\n",
    "grid_parms = dict(learning_rate = learning, \n",
    "                  n_estimators = n_estimators, \n",
    "                  max_depth = max_depth)\n",
    "grid_search = GridSearchCV(reg, grid_parms, scoring = 'neg_mean_squared_error', n_jobs = -1, verbose = 1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# 這樣會有 4 * 4 * 4 = 64 種參數組合，再搭配 5 組切割的資料，總共有 64 * 5 = 320 總可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " best loss: -3249.328994113577, HPs:{'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(f' best loss: {grid_search.best_score_}, HPs:{grid_search.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search CV Hyperparameter tuning\n",
    "> 也可以給一個分佈隨機去裡面抽~ [ref](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score=nan,\n",
       "                   estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                       criterion='friedman_mse',\n",
       "                                                       init=None,\n",
       "                                                       learning_rate=0.1,\n",
       "                                                       loss='ls', max_depth=3,\n",
       "                                                       max_features=None,\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=2,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=100...\n",
       "                                                       random_state=20,\n",
       "                                                       subsample=1.0,\n",
       "                                                       tol=0.0001,\n",
       "                                                       validation_fraction=0.1,\n",
       "                                                       verbose=0,\n",
       "                                                       warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.001, 0.01, 0.1, 1],\n",
       "                                        'max_depth': [1, 3, 5, 7],\n",
       "                                        'n_estimators': [50, 100, 200, 300]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='neg_mean_squared_error',\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning = [0.001, 0.01, 0.1, 1]\n",
    "n_estimators = [50, 100, 200, 300]\n",
    "max_depth = [1, 3, 5, 7]\n",
    "grid_parms = dict(learning_rate = learning, \n",
    "                  n_estimators = n_estimators, \n",
    "                  max_depth = max_depth)\n",
    "random_search = RandomizedSearchCV(reg, grid_parms, scoring = 'neg_mean_squared_error', n_jobs = -1, verbose = 1)\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# 這樣會有 4 * 4 * 4 = 64 種參數組合，再搭配 5 組切割的資料，總共有 64 * 5 = 320 總可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " best loss: -3436.5317447592324, HPs:{'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(f' best loss: {random_search.best_score_}, HPs:{random_search.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build model with best HPs\n",
    "> 雖然 train loss 上升了不少，但是 test loss 卻有下降。也許代表原本的低 train loss 是 overfitting 造成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2235.5237932523937\n",
      "test loss: 2812.9857279113453\n"
     ]
    }
   ],
   "source": [
    "reg = GradientBoostingRegressor(random_state = 20,\n",
    "                                learning_rate = grid_search.best_params_['learning_rate'],\n",
    "                                max_depth = grid_search.best_params_['max_depth'],\n",
    "                                n_estimators = grid_search.best_params_['n_estimators'])\n",
    "\n",
    "# reg = grid_search.best_estimator_  # 這樣也可以~\n",
    "# reg = random_search.best_estimator_\n",
    "\n",
    "reg.fit(x_train, y_train)\n",
    "y_pred = reg.predict(x_test)\n",
    "print(f'train loss: {metrics.mean_squared_error(y_train, reg.predict(x_train))}')\n",
    "print(f'test loss: {metrics.mean_squared_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = np.mean(wine.data, axis = 0)\n",
    "x_std = np.std(wine.data, axis = 0)\n",
    "x = np.empty(wine.data.shape)\n",
    "\n",
    "for i in range(x.shape[1]):\n",
    "    for j in range(x.shape[0]):\n",
    "        if x_std[i] != 0:\n",
    "            x[j][i] = (wine.data[j][i] - x_mean[i]) / x_std[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 1.0\n",
      "test accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, wine.target, test_size = 0.25, random_state = 45)\n",
    "clf = LogisticRegression(random_state = 1)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(f'train accuracy: {metrics.accuracy_score(y_train, clf.predict(x_train))}')\n",
    "print(f'test accuracy: {metrics.accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=1, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 10], 'max_iter': [50, 100, 200, 300],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       "                         'tol': [1e-05, 0.0001, 0.001]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty = ['l1', 'l2', 'elasticnet', 'none']\n",
    "tol = [1e-5, 1e-4, 1e-3]\n",
    "C = [0.1, 1, 10]\n",
    "max_iter = [50, 100, 200, 300]\n",
    "grid_parms = dict(penalty = penalty, \n",
    "                  tol = tol, \n",
    "                  C = C,\n",
    "                  max_iter = max_iter)\n",
    "grid_search = GridSearchCV(clf, grid_parms, n_jobs = -1, verbose = 1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "# 這樣會有 4 * 3 * 3 * 4 = 72 種參數組合，再搭配 5 組切割的資料，總共有 72 * 5 = 360 總可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " best loss: 0.9777777777777779, HPs:{'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 'tol': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "print(f' best loss: {grid_search.best_score_}, HPs:{grid_search.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bulid model with best HPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.9924812030075187\n",
      "test loss: 1.0\n"
     ]
    }
   ],
   "source": [
    "clf = grid_search.best_estimator_  \n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(f'train loss: {metrics.accuracy_score(y_train, clf.predict(x_train))}')\n",
    "print(f'test loss: {metrics.accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
